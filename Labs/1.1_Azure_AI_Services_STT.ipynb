{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quickstart: Using the Speech Service from Python\n",
    "\n",
    "This sample shows how to use the Speech Service through the Speech SDK for Python. It illustrates how the SDK can be used to recognize speech from microphone input.\n",
    "\n",
    "See the [accompanying article](https://docs.microsoft.com/azure/cognitive-services/speech-service/quickstart-python) on the SDK documentation page for step-by-step instructions.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before you get started, here's a list of prerequisites:\n",
    "\n",
    "* A subscription key for the Speech service. \n",
    "\n",
    "### Install Libraries:\n",
    "* On Ubuntu 16.04 or 18.04, run the following commands for the installation of required packages:\n",
    "  ```sh\n",
    "  sudo apt-get update\n",
    "  sudo apt-get install libssl-dev libasound2\n",
    "  ```\n",
    "* On Debian 9, run the following commands for the installation of required packages:\n",
    "  ```sh\n",
    "  sudo apt install libgstreamer1.0-0 \\\n",
    "  gstreamer1.0-plugins-base \\\n",
    "  gstreamer1.0-plugins-good \\\n",
    "  gstreamer1.0-plugins-bad \\\n",
    "  gstreamer1.0-plugins-ugly\n",
    "  ```\n",
    "*\n",
    "## Get the Speech SDK Python Package\n",
    "\n",
    "**By downloading the Microsoft Cognitive Services Speech SDK, you acknowledge its license, see [Speech SDK license agreement](https://aka.ms/csspeech/license).**\n",
    "\n",
    "The Cognitive Services Speech SDK Python package can be installed from [pyPI](https://pypi.org/) using this command:\n",
    "\n",
    "```sh\n",
    "pip install azure-cognitiveservices-speech\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech Recognition Using the Speech SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, set up some general items. Import the Speech SDK Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azure.cognitiveservices.speech as speechsdk\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Azure AI Services Speech Endpoint: westeurope\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "if load_dotenv():\n",
    "    print(\"Found Azure AI Services Speech Endpoint: \" + os.getenv(\"AZURE_AI_SPEECH_REGION\"))\n",
    "else: \n",
    "    print(\"Azure AI Services Speech Endpoint not found. Have you configured the .env file?\")\n",
    "    \n",
    "service_region = os.getenv(\"AZURE_AI_SPEECH_REGION\")\n",
    "speech_key = os.getenv(\"AZURE_AI_SPEECH_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs about the podcast\n",
    "podcast_url = \"https://www.microsoft.com/behind-the-tech\"\n",
    "podcast_audio_file = \"../data/PodcastSnippet.mp3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an instance of a speech config with specified subscription key and service region.\n",
    "Replace with your own subscription key and service region (e.g., \"westus\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a recognizer with the given settings. Since no explicit audio config is specified, the default microphone will be used (make sure the audio settings are correct)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starts speech recognition, and returns after a single utterance is recognized. The end of a\n",
    "single utterance is determined by listening for silence at the end or until a maximum of 15\n",
    "seconds of audio is processed.  The task returns the recognition text as result. \n",
    "Note: Since `recognize_once()` returns only a single utterance, it is suitable only for single\n",
    "shot recognition like command or query. \n",
    "For long-running multi-utterance recognition, use `start_continuous_recognition()` instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  This code is needet to process compressed files like MP3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryFileReaderCallback(speechsdk.audio.PullAudioInputStreamCallback):\n",
    "    def __init__(self, filename: str):\n",
    "        super().__init__()\n",
    "        self._file_h = open(filename, \"rb\")\n",
    "\n",
    "    def read(self, buffer: memoryview) -> int:\n",
    "        try:\n",
    "            size = buffer.nbytes\n",
    "            frames = self._file_h.read(size)\n",
    "            buffer[:len(frames)] = frames\n",
    "\n",
    "            return len(frames)\n",
    "        except Exception as ex:\n",
    "            print('Exception in `read`: {}'.format(ex))\n",
    "            raise\n",
    "\n",
    "    def close(self) -> None:\n",
    "        print('closing file')\n",
    "        try:\n",
    "            self._file_h.close()\n",
    "        except Exception as ex:\n",
    "            print('Exception in `close`: {}'.format(ex))\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speech recognition from mp3 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = []\n",
    "def speech_recognizer_recognised_cb(evt: speechsdk.SpeechRecognitionEventArgs):\n",
    "    if evt.result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "        print('\\tRecognised text={}'.format(evt.result.text))\n",
    "        all_results.append(evt.result.text)\n",
    "    elif evt.result.reason == speechsdk.ResultReason.NoMatch:\n",
    "        print('\\tNOMATCH: Speech could not be TRANSCRIBED: {}'.format(evt.result.no_match_details))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_recognize_continuous_from_file(filename):\n",
    "    \"\"\"performs continuous speech recognition with input from an audio file\"\"\"\n",
    "    # <SpeechContinuousRecognitionWithFile>\n",
    "# Creates an audio stream format. For an example we are using MP3 compressed file here\n",
    "    compressed_format = speechsdk.audio.AudioStreamFormat(compressed_stream_format=speechsdk.AudioStreamContainerFormat.MP3)\n",
    "    callback = BinaryFileReaderCallback(filename=filename)\n",
    "    stream = speechsdk.audio.PullAudioInputStream(stream_format=compressed_format, pull_stream_callback=callback)\n",
    "\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n",
    "    audio_config = speechsdk.audio.AudioConfig(stream=stream)\n",
    "\n",
    "    # Creates a speech recognizer using a file as audio input, also specify the speech language\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config, audio_config)\n",
    "    \n",
    "    done = False\n",
    "    text=\"\"\n",
    "\n",
    "    def stop_cb(evt: speechsdk.SessionEventArgs):\n",
    "        \"\"\"callback that signals to stop continuous recognition upon receiving an event `evt`\"\"\"\n",
    "        #print('CLOSING on {}'.format(evt))\n",
    "        nonlocal done\n",
    "        done = True\n",
    "\n",
    "    # Connect callbacks to the events fired by the speech recognizer\n",
    "    #speech_recognizer.recognized.connect(lambda evt: print('RECOGNIZED: {}'.format(evt)))\n",
    "    speech_recognizer.recognized.connect(speech_recognizer_recognised_cb)\n",
    "    speech_recognizer.session_started.connect(lambda evt: print('SessionStarted event'))\n",
    "    speech_recognizer.session_stopped.connect(lambda evt: print('SessionStopped event'))\n",
    "    speech_recognizer.canceled.connect(lambda evt: print('Canceled event'))\n",
    "    # Stop continuous recognition on either session stopped or canceled events\n",
    "    speech_recognizer.session_stopped.connect(stop_cb)\n",
    "    speech_recognizer.canceled.connect(stop_cb)\n",
    "\n",
    "    # Start continuous speech recognition\n",
    "    speech_recognizer.start_continuous_recognition()\n",
    "    while not done:\n",
    "        time.sleep(.5)\n",
    "\n",
    "    speech_recognizer.stop_continuous_recognition()\n",
    "    return\n",
    "    # </SpeechContinuousRecognitionWithFile>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SessionStarted event\n",
      "\tRecognised text=Neil deGrasse Tyson is one of America's best known astrophysicists and a beloved educator and advocate for the sciences. He has a great talent for presenting complex concepts in a clear and accessible manner. He's the head of the Hayden Planetarium and has been the director there since 1996. He's hosted numerous space related TV and radio programs, published several books, and host the podcast Star Talk Radio. I am thrilled to have you on the podcast today, Neil.\n",
      "\tRecognised text=Well, thanks. Thanks for having me. Thank you. Why do you take you this long to invite me? I just want to know. Shame, shame, shame on me. I'm not hidden right. You aren't. And and I will say, when I started this podcast and when I wrote my book and I started doing this very uncomfortable thing for me, which is trying to talk more about technology in the public, you were literally my role model. I said, you know, Neil deGrasse Tyson does such a wonderful job.\n",
      "\tRecognised text=Communicating about the importance and the value of science to the public, We don't have people doing that about software and technology related things. No, you don't. That's right.\n",
      "\tRecognised text=And I I I took you as a role model. And I Granted, I'm nowhere near as charming and as effective a communicator as you are, but I'm trying to do my best.\n",
      "Canceled event\n",
      "SessionStopped event\n",
      "Recognized text:\n",
      "[\"Neil deGrasse Tyson is one of America's best known astrophysicists and a beloved educator and advocate for the sciences. He has a great talent for presenting complex concepts in a clear and accessible manner. He's the head of the Hayden Planetarium and has been the director there since 1996. He's hosted numerous space related TV and radio programs, published several books, and host the podcast Star Talk Radio. I am thrilled to have you on the podcast today, Neil.\", \"Well, thanks. Thanks for having me. Thank you. Why do you take you this long to invite me? I just want to know. Shame, shame, shame on me. I'm not hidden right. You aren't. And and I will say, when I started this podcast and when I wrote my book and I started doing this very uncomfortable thing for me, which is trying to talk more about technology in the public, you were literally my role model. I said, you know, Neil deGrasse Tyson does such a wonderful job.\", \"Communicating about the importance and the value of science to the public, We don't have people doing that about software and technology related things. No, you don't. That's right.\", \"And I I I took you as a role model. And I Granted, I'm nowhere near as charming and as effective a communicator as you are, but I'm trying to do my best.\"]\n"
     ]
    }
   ],
   "source": [
    "all_results = []\n",
    "speech_recognize_continuous_from_file(podcast_audio_file)\n",
    "print(\"Recognized text:\")\n",
    "print(all_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file path\n",
    "file_path = \"transcript_Azure_STT.txt\"\n",
    "\n",
    "# Write the content to the file\n",
    "with open(file_path, \"w\") as file:\n",
    "    file.write(\"\".join(all_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get transcription with speaker recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conversation_transcriber_recognition_canceled_cb(evt: speechsdk.SessionEventArgs):\n",
    "    print('Canceled event')\n",
    "\n",
    "def conversation_transcriber_session_stopped_cb(evt: speechsdk.SessionEventArgs):\n",
    "    print('SessionStopped event')\n",
    "\n",
    "def conversation_transcriber_transcribed_cb(evt: speechsdk.SpeechRecognitionEventArgs):\n",
    "    print('TRANSCRIBED:')\n",
    "    if evt.result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "        print('\\tSpeaker ID={}'.format(evt.result.speaker_id))\n",
    "        print('\\tText={}'.format(evt.result.text))\n",
    "        all_results.append('\\n'+evt.result.speaker_id+': ')\n",
    "        all_results.append(evt.result.text)\n",
    "    elif evt.result.reason == speechsdk.ResultReason.NoMatch:\n",
    "        print('\\tNOMATCH: Speech could not be TRANSCRIBED: {}'.format(evt.result.no_match_details))\n",
    "\n",
    "def conversation_transcriber_session_started_cb(evt: speechsdk.SessionEventArgs):\n",
    "    print('SessionStarted event')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SessionStarted event\n",
      "TRANSCRIBED:\n",
      "\tSpeaker ID=Guest-1\n",
      "\tText=Neil deGrasse Tyson is one of America's best known astrophysicists and a beloved educator and advocate for the sciences. He has a great talent for presenting complex concepts in a clear and accessible manner. He's the head of the Hayden Planetarium and has been the director there since 1996. He's hosted numerous space related TV and radio programs, published several books, and host the podcast Star Talk Radio. I am thrilled to have you on the podcast today, Neil.\n",
      "TRANSCRIBED:\n",
      "\tSpeaker ID=Guest-2\n",
      "\tText=Well, thanks. Thanks for having me. Thank you. Why do you take you this long to?\n",
      "TRANSCRIBED:\n",
      "\tSpeaker ID=Guest-1\n",
      "\tText=Invite me. I just wanna know. Shame, shame, shame on me.\n",
      "TRANSCRIBED:\n",
      "\tSpeaker ID=Guest-2\n",
      "\tText=I'm not hidden right.\n",
      "TRANSCRIBED:\n",
      "\tSpeaker ID=Guest-1\n",
      "\tText=You aren't. And and I will say, when I started this podcast and when I wrote my book and I started doing this very uncomfortable thing for me, which is trying to talk more about technology in the public, you were literally my role model. I said, you know, Neil deGrasse Tyson does such a wonderful job.\n",
      "TRANSCRIBED:\n",
      "\tSpeaker ID=Guest-1\n",
      "\tText=Communicating about the importance and the value of science to the public. We don't have people doing that about software and technology related.\n",
      "TRANSCRIBED:\n",
      "\tSpeaker ID=Guest-2\n",
      "\tText=Things. No, you don't. That's right.\n",
      "TRANSCRIBED:\n",
      "\tSpeaker ID=Guest-1\n",
      "\tText=And I I I took you as a role model. And I Granted, I'm nowhere near as charming and as effective a communicator as you are, but I'm trying to do my best.\n",
      "Canceled event\n",
      "CLOSING on ConversationTranscriptionCanceledEventArgs(session_id=2f9f56a202124b50b08934e997bde7e2, result=ConversationTranscriptionResult(result_id=04590c5f572843bda0799f876a7a4a73, speaker_id=, text=, reason=ResultReason.Canceled))\n",
      "SessionStopped event\n",
      "CLOSING on SessionEventArgs(session_id=2f9f56a202124b50b08934e997bde7e2)\n"
     ]
    }
   ],
   "source": [
    "def recognize_from_file(filename):\n",
    "  # Creates an audio stream format. For an example we are using MP3 compressed file here\n",
    "    compressed_format = speechsdk.audio.AudioStreamFormat(compressed_stream_format=speechsdk.AudioStreamContainerFormat.MP3)\n",
    "    callback = BinaryFileReaderCallback(filename=filename)\n",
    "    stream = speechsdk.audio.PullAudioInputStream(stream_format=compressed_format, pull_stream_callback=callback)\n",
    "\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n",
    "    speech_config.speech_recognition_language=\"en-US\"\n",
    "    audio_config = speechsdk.audio.AudioConfig(stream=stream)\n",
    "\n",
    "    conversation_transcriber = speechsdk.transcription.ConversationTranscriber(speech_config=speech_config, audio_config=audio_config)\n",
    "\n",
    "    transcribing_stop = False\n",
    "\n",
    "    def stop_cb(evt: speechsdk.SessionEventArgs):\n",
    "        #\"\"\"callback that signals to stop continuous recognition upon receiving an event `evt`\"\"\"\n",
    "        print('CLOSING on {}'.format(evt))\n",
    "        nonlocal transcribing_stop\n",
    "        transcribing_stop = True\n",
    "\n",
    "    # Connect callbacks to the events fired by the conversation transcriber\n",
    "    conversation_transcriber.transcribed.connect(conversation_transcriber_transcribed_cb)\n",
    "    conversation_transcriber.session_started.connect(conversation_transcriber_session_started_cb)\n",
    "    conversation_transcriber.session_stopped.connect(conversation_transcriber_session_stopped_cb)\n",
    "    conversation_transcriber.canceled.connect(conversation_transcriber_recognition_canceled_cb)\n",
    "    # stop transcribing on either session stopped or canceled events\n",
    "    conversation_transcriber.session_stopped.connect(stop_cb)\n",
    "    conversation_transcriber.canceled.connect(stop_cb)\n",
    "\n",
    "    conversation_transcriber.start_transcribing_async()\n",
    "\n",
    "    # Waits for completion.\n",
    "    while not transcribing_stop:\n",
    "        time.sleep(.5)\n",
    "\n",
    "    conversation_transcriber.stop_transcribing_async()\n",
    "\n",
    "# Main\n",
    "\n",
    "try:\n",
    "    all_results = []\n",
    "    recognize_from_file(podcast_audio_file)\n",
    "except Exception as err:\n",
    "    print(\"Encountered exception. {}\".format(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file path\n",
    "file_path = \"transcript_Azure_STT_with_speaker.txt\"\n",
    "\n",
    "# Write the content to the file\n",
    "with open(file_path, \"w\") as file:\n",
    "    file.write(\"\".join(all_results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
