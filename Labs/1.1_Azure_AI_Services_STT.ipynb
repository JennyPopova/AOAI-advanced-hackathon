{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview: Using the Speech Service from Python\n",
    "\n",
    "This lab shows how to use the Speech Service through the Speech SDK for Python. It illustrates how the SDK can be used to recognize speech from file input.\n",
    "\n",
    "See the [accompanying article](https://learn.microsoft.com/en-us/azure/ai-services/speech-service/index-speech-to-text) for more details.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before you get started, here's a list of prerequisites:\n",
    "\n",
    "* A subscription key for the Speech service. \n",
    "\n",
    "### Install Libraries in Terminal:\n",
    "* gstreamer:\n",
    "  ```sh\n",
    "  sudo apt install libgstreamer1.0-0 \\\n",
    "  gstreamer1.0-plugins-base \\\n",
    "  gstreamer1.0-plugins-good \\\n",
    "  gstreamer1.0-plugins-bad \\\n",
    "  gstreamer1.0-plugins-ugly\n",
    "  ```\n",
    "\n",
    "### Speech SDK Python Package\n",
    "\n",
    "**By downloading the Microsoft Cognitive Services Speech SDK, you acknowledge its license, see [Speech SDK license agreement](https://aka.ms/csspeech/license).**\n",
    "\n",
    "Speech SDK Python Package should be installed together with other libraries via `requirementx.txt`\n",
    "In case the pachage was not installed, the Cognitive Services Speech SDK Python package can be installed from [pyPI](https://pypi.org/) using this command:\n",
    "\n",
    "```sh\n",
    "pip install azure-cognitiveservices-speech\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech Recognition Using the Speech SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, set up some general items. Import the Speech SDK Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azure.cognitiveservices.speech as speechsdk\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load environment variables\n",
    "The provided code is importing the `load_dotenv` function from the `dotenv` module and using it to load environment variables from a `.env`\n",
    "To get access to Azure Speech Service via python SDK we need **Access Key** and **Servie Region**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "if load_dotenv():\n",
    "    print(\"Found Azure AI Services Speech Endpoint: \" + os.getenv(\"AZURE_AI_SPEECH_REGION\"))\n",
    "else: \n",
    "    print(\"Azure AI Services Speech Endpoint not found. Have you configured the .env file?\")\n",
    "    \n",
    "service_region = os.getenv(\"AZURE_AI_SPEECH_REGION\")\n",
    "speech_key = os.getenv(\"AZURE_AI_SPEECH_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get input file\n",
    "This Python code snippet is used to read podcast audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs about the podcast\n",
    "podcast_url = \"https://www.microsoft.com/behind-the-tech\"\n",
    "podcast_audio_file = \"../data/PodcastSnippet.mp3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  This code is needed to process compressed files like MP3. \n",
    "If you use not compressed file formats, like `.wav` there is no need for additional processing, Azure Speech Service can handle it OOTB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryFileReaderCallback(speechsdk.audio.PullAudioInputStreamCallback):\n",
    "    def __init__(self, filename: str):\n",
    "        super().__init__()\n",
    "        self._file_h = open(filename, \"rb\")\n",
    "\n",
    "    def read(self, buffer: memoryview) -> int:\n",
    "        try:\n",
    "            size = buffer.nbytes\n",
    "            frames = self._file_h.read(size)\n",
    "            buffer[:len(frames)] = frames\n",
    "\n",
    "            return len(frames)\n",
    "        except Exception as ex:\n",
    "            print('Exception in `read`: {}'.format(ex))\n",
    "            raise\n",
    "\n",
    "    def close(self) -> None:\n",
    "        print('closing file')\n",
    "        try:\n",
    "            self._file_h.close()\n",
    "        except Exception as ex:\n",
    "            print('Exception in `close`: {}'.format(ex))\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Speech recognition from mp3 file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This code is needed if you want special processin for real-time speech recognition\n",
    "In this code snippet we are checking status of real-time recognition and collecting all pieces for further processing.\n",
    "If you use bach processing, instead of real-time, full outpur will be provided by the service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = []\n",
    "def speech_recognizer_recognised_cb(evt: speechsdk.SpeechRecognitionEventArgs):\n",
    "    if evt.result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "        print('\\tRecognised text={}'.format(evt.result.text))\n",
    "        all_results.append(evt.result.text)\n",
    "    elif evt.result.reason == speechsdk.ResultReason.NoMatch:\n",
    "        print('\\tNOMATCH: Speech could not be TRANSCRIBED: {}'.format(evt.result.no_match_details))\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speech recognition from mp3 file\n",
    "This Python function `speech_recognize_continuous_from_file` performs continuous speech recognition on an audio file using Azure's Speech SDK.\n",
    "\n",
    "- The function takes one argument, `filename`, which is the path to the audio file.\n",
    "\n",
    "- An audio stream format is created for a compressed MP3 file using `speechsdk.audio.AudioStreamFormat`.\n",
    "\n",
    "- A callback is created using the `BinaryFileReaderCallback` with the filename as an argument. This callback will read the binary data from the file.\n",
    "\n",
    "- A speech configuration is created using `speechsdk.SpeechConfig` with a subscription key and service region.\n",
    "\n",
    "- An audio configuration is created using `speechsdk.audio.AudioConfig` with the audio stream.\n",
    "\n",
    "- A speech recognizer is created using `speechsdk.SpeechRecognizer` with the speech and audio configurations.\n",
    "\n",
    "- Several event handlers are connected to the speech recognizer. These handlers will be called when the corresponding events are fired by the recognizer.\n",
    "\n",
    "- Continuous speech recognition is started with `speech_recognizer.start_continuous_recognition()`.\n",
    "\n",
    "- The function waits until `done` is `True`, checking every 0.5 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_recognize_continuous_from_file(filename):\n",
    "    \"\"\"performs continuous speech recognition with input from an audio file\"\"\"\n",
    "    # <SpeechContinuousRecognitionWithFile>\n",
    "\n",
    "# Creates an audio stream format. For an example we are using MP3 compressed file here\n",
    "    compressed_format = speechsdk.audio.AudioStreamFormat(compressed_stream_format=speechsdk.AudioStreamContainerFormat.MP3)\n",
    "    callback = BinaryFileReaderCallback(filename=filename)\n",
    "    stream = speechsdk.audio.PullAudioInputStream(stream_format=compressed_format, pull_stream_callback=callback)\n",
    "\n",
    "# Creates a speech config with specified subscription key and service region.\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n",
    "    audio_config = speechsdk.audio.AudioConfig(stream=stream)\n",
    "\n",
    "# Creates a speech recognizer using a file as audio input, also specify the speech language\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config, audio_config)\n",
    "    \n",
    "    done = False\n",
    "    text=\"\"\n",
    "\n",
    "    def stop_cb(evt: speechsdk.SessionEventArgs):\n",
    "        \"\"\"callback that signals to stop continuous recognition upon receiving an event `evt`\"\"\"\n",
    "        #print('CLOSING on {}'.format(evt))\n",
    "        nonlocal done\n",
    "        done = True\n",
    "\n",
    "    # Connect callbacks to the events fired by the speech recognizer\n",
    "    #speech_recognizer.recognized.connect(lambda evt: print('RECOGNIZED: {}'.format(evt)))\n",
    "    speech_recognizer.recognized.connect(speech_recognizer_recognised_cb)\n",
    "    speech_recognizer.session_started.connect(lambda evt: print('SessionStarted event'))\n",
    "    speech_recognizer.session_stopped.connect(lambda evt: print('SessionStopped event'))\n",
    "    speech_recognizer.canceled.connect(lambda evt: print('Canceled event'))\n",
    "    # Stop continuous recognition on either session stopped or canceled events\n",
    "    speech_recognizer.session_stopped.connect(stop_cb)\n",
    "    speech_recognizer.canceled.connect(stop_cb)\n",
    "\n",
    "    # Start continuous speech recognition\n",
    "    speech_recognizer.start_continuous_recognition()\n",
    "    while not done:\n",
    "        time.sleep(.5)\n",
    "\n",
    "    speech_recognizer.stop_continuous_recognition()\n",
    "    return\n",
    "    # </SpeechContinuousRecognitionWithFile>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run speech regonition for mp3 audio file\n",
    "Here we run Speech Recognition and collect all the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = []\n",
    "speech_recognize_continuous_from_file(podcast_audio_file)\n",
    "print(\"Recognized text:\")\n",
    "print(all_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results to file\n",
    "This Python code snippet is used to write the transcribed text to `\"transcript_Azure_STT.txt\"` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file path\n",
    "file_path = \"transcript_Azure_STT.txt\"\n",
    "\n",
    "# Write the content to the file\n",
    "with open(file_path, \"w\") as file:\n",
    "    file.write(\"\".join(all_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get transcription with speaker recognition\n",
    "\n",
    "The Azure Speech to Text service offers several powerful features:\n",
    "\n",
    "- **High-Quality Transcription**: Accurately transcribe spoken audio to text in over 100 languages and variants. It provides state-of-the-art speech recognition for high-quality transcription.\n",
    "\n",
    "- **Customizable Models**: Tailor the speech models to your specific needs. You can add domain-specific terminology by including specific words in your base vocabulary or even build your own custom speech-to-text models. This flexibility allows you to overcome barriers like background noise, accents, or unique vocabulary.\n",
    "\n",
    "- **Speaker Diarization**: Determine who said what and when by using speaker diarization. This feature helps differentiate speakers in the transcribed text.\n",
    "\n",
    "- **Automatic Formatting and Punctuation**: Get readable transcripts with automatic formatting and proper punctuation.\n",
    "\n",
    "For detailed documentation and tutorials, visit the [Speech to Text documentation page](https://docs.microsoft.com/azure/cognitive-services/speech-service/index-speech-to-text)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This code is needed if you want special processin for real-time speech recognition\n",
    "In this code snippet we are checking status of real-time recognition and collecting all pieces for further processing.\n",
    "If you use bach processing, instead of real-time, full outpur will be provided by the service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conversation_transcriber_recognition_canceled_cb(evt: speechsdk.SessionEventArgs):\n",
    "    print('Canceled event')\n",
    "\n",
    "def conversation_transcriber_session_stopped_cb(evt: speechsdk.SessionEventArgs):\n",
    "    print('SessionStopped event')\n",
    "\n",
    "def conversation_transcriber_transcribed_cb(evt: speechsdk.SpeechRecognitionEventArgs):\n",
    "    print('TRANSCRIBED:')\n",
    "    if evt.result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "        print('\\tSpeaker ID={}'.format(evt.result.speaker_id))\n",
    "        print('\\tText={}'.format(evt.result.text))\n",
    "        all_results.append('\\n'+evt.result.speaker_id+': ')\n",
    "        all_results.append(evt.result.text)\n",
    "    elif evt.result.reason == speechsdk.ResultReason.NoMatch:\n",
    "        print('\\tNOMATCH: Speech could not be TRANSCRIBED: {}'.format(evt.result.no_match_details))\n",
    "\n",
    "def conversation_transcriber_session_started_cb(evt: speechsdk.SessionEventArgs):\n",
    "    print('SessionStarted event')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcribe audio file with diarization\n",
    "This Python function `recognize_from_file` performs speech recognition on an audio file using Azure's Speech SDK and transcribes a conversation from the audio file.\n",
    "\n",
    "- The function takes one argument, `filename`, which is the path to the audio file.\n",
    "- An audio stream format is created for a compressed MP3 file using `speechsdk.audio.AudioStreamFormat`.\n",
    "- A callback is created using the `BinaryFileReaderCallback` with the filename as an argument. This callback will read the binary data from the file.\n",
    "- A speech configuration is created using `speechsdk.SpeechConfig` with a subscription key and service region. The speech recognition language is set to \"en-US\".\n",
    "- An audio configuration is created using `speechsdk.audio.AudioConfig` with the audio stream.\n",
    "- A conversation transcriber is created using `speechsdk.transcription.ConversationTranscriber` with the speech and audio configurations.\n",
    "\n",
    "- Several event handlers are connected to the conversation transcriber. These handlers will be called when the corresponding events are fired by the transcriber.\n",
    "- The function waits until `transcribing_stop` is `True`, checking every 0.5 seconds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_from_file(filename):\n",
    "  # Creates an audio stream format. For an example we are using MP3 compressed file here\n",
    "    compressed_format = speechsdk.audio.AudioStreamFormat(compressed_stream_format=speechsdk.AudioStreamContainerFormat.MP3)\n",
    "    callback = BinaryFileReaderCallback(filename=filename)\n",
    "    stream = speechsdk.audio.PullAudioInputStream(stream_format=compressed_format, pull_stream_callback=callback)\n",
    "\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n",
    "    speech_config.speech_recognition_language=\"en-US\"\n",
    "    audio_config = speechsdk.audio.AudioConfig(stream=stream)\n",
    "\n",
    "    conversation_transcriber = speechsdk.transcription.ConversationTranscriber(speech_config=speech_config, audio_config=audio_config)\n",
    "\n",
    "    transcribing_stop = False\n",
    "\n",
    "    def stop_cb(evt: speechsdk.SessionEventArgs):\n",
    "        #\"\"\"callback that signals to stop continuous recognition upon receiving an event `evt`\"\"\"\n",
    "        print('CLOSING on {}'.format(evt))\n",
    "        nonlocal transcribing_stop\n",
    "        transcribing_stop = True\n",
    "\n",
    "    # Connect callbacks to the events fired by the conversation transcriber\n",
    "    conversation_transcriber.transcribed.connect(conversation_transcriber_transcribed_cb)\n",
    "    conversation_transcriber.session_started.connect(conversation_transcriber_session_started_cb)\n",
    "    conversation_transcriber.session_stopped.connect(conversation_transcriber_session_stopped_cb)\n",
    "    conversation_transcriber.canceled.connect(conversation_transcriber_recognition_canceled_cb)\n",
    "    # stop transcribing on either session stopped or canceled events\n",
    "    conversation_transcriber.session_stopped.connect(stop_cb)\n",
    "    conversation_transcriber.canceled.connect(stop_cb)\n",
    "\n",
    "    conversation_transcriber.start_transcribing_async()\n",
    "\n",
    "    # Waits for completion.\n",
    "    while not transcribing_stop:\n",
    "        time.sleep(.5)\n",
    "\n",
    "    conversation_transcriber.stop_transcribing_async()\n",
    "\n",
    "# Main\n",
    "\n",
    "try:\n",
    "    all_results = []\n",
    "    recognize_from_file(podcast_audio_file)\n",
    "except Exception as err:\n",
    "    print(\"Encountered exception. {}\".format(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results to file\n",
    "This Python code snippet is used to write the transcribed text to `\"transcript_Azure_STT_with_speaker.txt\"` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file path\n",
    "file_path = \"transcript_Azure_STT_with_speaker.txt\"\n",
    "\n",
    "# Write the content to the file\n",
    "with open(file_path, \"w\") as file:\n",
    "    file.write(\"\".join(all_results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
