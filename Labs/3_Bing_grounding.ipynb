{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Overview\n",
        "\n",
        "The process of grounding involves integrating a language model (such as GPT) with specific data sources to enhance its performance and relevance. In the case of Bing Chat, Microsoft has employed this technique to create a more accurate and context-aware search experience by combining OpenAI’s GPT model with Bing search results.\n",
        "\n",
        "Here’s how it works:\n",
        "\n",
        "GPT Model: Large language models like GPT-4 are trained on data up to a certain point in time. For instance, ChatGPT’s training data stopped at some point in 2021.\n",
        "Bing Data: Bing, on the other hand, has a vast index of web pages, ranking algorithms, and answer results. It provides relevant information based on user queries.\n",
        "You can use variouse techniques to bridges the gap between GPT and Bing to combines the power of both to generate accurate and rich answers for your queries.\n",
        "\n",
        "### Bing Search API:\n",
        "The Bing Search API is a powerful tool provided by Microsoft, enabling developers to integrate Bing's search capabilities directly into their applications. This API allows access to a wide range of search results, including web pages, images, videos, and news, providing developers with a seamless way to incorporate Bing's search functionality into their own projects."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import python libararies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1710955352321
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from langchain.chains import TransformChain\n",
        "import requests\n",
        "import json\n",
        "from openai import AzureOpenAI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get Environment variables\n",
        "The provided code is importing the `load_dotenv` function from the `dotenv` module and using it to load environment variables from a `.env`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1710955262803
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables\n",
        "if load_dotenv():\n",
        "    print(\"Found Azure OpenAI API Base Endpoint: \" + os.getenv(\"AZURE_OPENAI_ENDPOINT\"))\n",
        "else: \n",
        "    print(\"Azure OpenAI API Base Endpoint not found. Have you configured the .env file?\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### set up the Bing Search API\n",
        "This Python code snippet is used to set up the Bing Search API.\n",
        "- The `bing_search_url` variable is set to base URL for the Bing Search API.\n",
        "- The `bing_subscription_key` variable is set to the value of the \"BING_SUBSCRIPTION_KEY\" environment variable. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1710955265935
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "bing_search_url = \"https://api.bing.microsoft.com/v7.0/search\"\n",
        "bing_subscription_key = os.getenv(\"BING_SUBSCRIPTION_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get Guest name from the file saved in previous lab\n",
        "To retrieve the guest name from the file saved in the previous lab, you can use the following code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1710955272314
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Open the file\n",
        "with open('guest_name.txt', 'r') as f:\n",
        "    guest = f.read()\n",
        "\n",
        "# Print the content\n",
        "print(guest)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Test Bing Search \n",
        "Lets'see what Bing Search returns as search results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define function to perform Bing search\n",
        "This Python function, `search_bing`, is used to perform a search using the Bing Search API.\n",
        "\n",
        "- The function takes one argument, `query`, which is the search query.\n",
        "- The `headers` dictionary is created with the key \"Ocp-Apim-Subscription-Key\" and the value of `bing_subscription_key`. This is used to authenticate the request to the Bing Search API.\n",
        "- The `requests.get` function sends a GET request to the Bing Search API.\n",
        "- The `response.raise_for_status` method is called to raise an exception if the HTTP request returned an unsuccessful status code.\n",
        "- A for loop is used to iterate over the search results. For each result, a dictionary is created with the keys \"title\", \"link\", and \"snippet\", and the corresponding values from the result. This dictionary is then appended to the `output` list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def search_bing(query):\n",
        "    \"\"\"\n",
        "    Perform a bing search against the given query\n",
        "\n",
        "    @param query: Search query\n",
        "    @return: List of search results\n",
        "\n",
        "    \"\"\"\n",
        "    headers = {\"Ocp-Apim-Subscription-Key\": bing_subscription_key}\n",
        "    params = {\"q\": query, \"textDecorations\": False}\n",
        "    response = requests.get(bing_search_url, headers=headers, params=params)\n",
        "    response.raise_for_status()\n",
        "    search_results = response.json()\n",
        "\n",
        "    output = []\n",
        "\n",
        "    for result in search_results[\"webPages\"][\"value\"]:\n",
        "        output.append({\"title\": result[\"name\"], \"link\": result[\"url\"], \"snippet\": result[\"snippet\"]})\n",
        "\n",
        "    return json.dumps(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test Bing search and evaluate the search results\n",
        "This Python code snippet is used to perform a search on Bing using the `search_bing` function with **\"Who is [guest]?\"**\n",
        "Look at the results Bing Search is returning.\n",
        "\n",
        "*You can experiment further and try your own queries*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "search_bing(\"Who is \"+guest+\"?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Test GPT model without grounding\n",
        "Let's see what GPT model returns without any grounding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Connect to Azure OpenAI service\n",
        "This Python code snippet is used to create a client for the Azure OpenAI service. The client is used to interact with the OpenAI API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "client = AzureOpenAI(\n",
        "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
        "    api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
        "    api_version = \"2023-12-01-preview\"\n",
        ")\n",
        "model =  os.getenv(\"AZURE_OPENAI_CHAT_MODEL\")\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create a prompt for GPT model\n",
        "*You can experiment further and try your own prompts*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "messages = [{\"role\": \"user\", \"content\": \"Who is \"+guest+\"?\"}]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Send request to GPT model\n",
        "This sends a request to the OpenAI API to generate a completion using the defined model and messages prompt created above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gpt_response = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=messages,\n",
        "        )  \n",
        "    \n",
        "bio = gpt_response.choices[0].message.content\n",
        "print(bio)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Grounding with Function Calling\n",
        "In Azure OpenAI, you can leverage the tools parameter to incorporate specific tools into your language model.\n",
        "- Specify the relevant tools based on your use case. These tools can be predefined internal functions or custom tools you create.\n",
        "- When making a request to the API, include the tools along with the user’s input (prompt).\n",
        "- The model will consider these tools during response generation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define Tools for GPT model, that include Bing search function\n",
        "This Python code snippet defines `tools` that will be used by GPT model. \n",
        "here we are describing  a function that can be used for searching Bing to get up-to-date information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"search_bing\",\n",
        "            \"description\": \"Searches bing to get up-to-date information about people\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"query\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The search query\",\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"query\"],\n",
        "            },\n",
        "        },\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Send request to GPT model and see if there any tools calling\n",
        "This sends a request to the OpenAI API to generate a completion using prompt and tools defined above.\n",
        "You can see the result GPT model is returning with function calling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        tools=tools,\n",
        "        tool_choice=\"auto\",  # auto is default, but we'll be explicit\n",
        "        )\n",
        "\n",
        "response_message = response.choices[0].message\n",
        "tool_calls = response_message.tool_calls\n",
        "print(response_message)\n",
        "print(tool_calls)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Go through function calling and extract messages to see Bing search results\n",
        "This Python code snippet is used to look the tool calls received and append the function's response to the conversation.\n",
        "\n",
        "A for loop is used to iterate over the `tool_calls`. For each `tool_call`:\n",
        "   - The corresponding function object is retrieved from `available_functions`\n",
        "   - The function's `response_message` is appended to the `messages` list to extend the conversation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if tool_calls:\n",
        "        # Step 3: call the function\n",
        "        # Note: the JSON response may not always be valid; be sure to handle errors\n",
        "        available_functions = {\n",
        "            \"search_bing\": search_bing,\n",
        "        }  # only one function in this example, but you can have multiple\n",
        "        messages.append(response_message)  # extend conversation with assistant's reply\n",
        "        # Step 4: send the info for each function call and function response to the model\n",
        "        for tool_call in tool_calls:\n",
        "            function_name = tool_call.function.name\n",
        "            function_to_call = available_functions[function_name]\n",
        "            function_args = json.loads(tool_call.function.arguments)\n",
        "            function_response = function_to_call(\n",
        "                query=function_args.get(\"query\")\n",
        "            )\n",
        "            messages.append(\n",
        "                {\n",
        "                    \"tool_call_id\": tool_call.id,\n",
        "                    \"role\": \"tool\",\n",
        "                    \"name\": function_name,\n",
        "                    \"content\": function_response,\n",
        "                }\n",
        "            )  # extend conversation with function response\n",
        "print(messages)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Ask GPT model to generate short bio of the person based on search results\n",
        "We have extended our messages with Bing Search responses. \n",
        "Let's ask GPT model to answer **\"Who is [guest]?\"** question using additional information.\n",
        "\n",
        "Compare with non-grounded answer from GPT model from the above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "second_response = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=messages,\n",
        "        )  # get a new response from the model where it can see the function response\n",
        "    \n",
        "bio = second_response.choices[0].message.content\n",
        "print(bio)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save guest biography to file\n",
        "This Python code snippet is used to write the guest's biography into `\"bio.txt\"` text file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Specify the file path\n",
        "file_path = \"bio.txt\"\n",
        "\n",
        "# Write the content to the file\n",
        "with open(file_path, \"w\") as file:\n",
        "    file.write(bio)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Grounding with LangChain\n",
        "Another approach to grounding can be LangChain Transform Chain. In this case, you clearly define that Bung Search query is part of your solution.\n",
        "### Transform Chain in LangChain:\n",
        "**Langchain** is a Python library that allows you to create powerful applications using language models and prompts.\n",
        "Langchain's **Transform Chain** is a dynamic and versatile feature that facilitates the seamless transformation of text data. Through a series of customizable linguistic operations, developers can construct intricate text processing pipelines. This transformative chain empowers users to preprocess, analyze, and manipulate textual information efficiently, offering a flexible and scalable solution for diverse language processing tasks within the Langchain framework."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define function to perform Bing search\n",
        "This Python function, `bing_grounding`, is used to perform a search using the Bing Search API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1710955358447
        }
      },
      "outputs": [],
      "source": [
        "def bing_grounding(input_dict:dict) -> dict:\n",
        "    print(\"Calling Bing Search API to get bio for guest...\\n\")\n",
        "    search_term = input_dict[\"guest\"]\n",
        "    print(\"Search term is \" + search_term)\n",
        "\n",
        "    headers = {\"Ocp-Apim-Subscription-Key\": bing_subscription_key}\n",
        "    params = {\"q\": search_term, \"textDecorations\": True, \"textFormat\": \"HTML\"}\n",
        "    response = requests.get(bing_search_url, headers=headers, params=params)\n",
        "    response.raise_for_status()\n",
        "    search_results = response.json()\n",
        "    #print(search_results)\n",
        "\n",
        "    # Parse out a bio.  \n",
        "    bio = search_results[\"webPages\"][\"value\"][0][\"snippet\"]\n",
        "    \n",
        "    print(\"Bio:\\n\")\n",
        "    print(bio)\n",
        "    print(\"\\n\")\n",
        "\n",
        "    return {\"bio\": bio}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1710955363255
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "bing_chain = TransformChain(input_variables=[\"guest\"], output_variables=[\"bio\"], transform=bing_grounding)\n",
        "bio = bing_chain.run(guest)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save another version of guest biography if you prefere it\n",
        "This Python code snippet is used to write the guest's biography into `\"bio1.txt\"` text file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1710525482460
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Specify the file path\n",
        "file_path = \"bio1.txt\"\n",
        "\n",
        "# Write the content to the file\n",
        "with open(file_path, \"w\") as file:\n",
        "    file.write(bio)"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
