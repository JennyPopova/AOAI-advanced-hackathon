{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "**DALL-E** is a powerful AI model that can generate and edit images based on natural language prompts. **Image client** is a Python library that allows you to interact with DALL-E and other image models using a simple and intuitive interface. GPT-4 is a state-of-the-art language model that can understand and generate natural language or code. By combining these three components, you can create amazing applications that use natural language to generate and manipulate images. For example, you can use GPT-4 to generate a prompt for DALL-E, such as “a cat wearing a hat”, and then use image client to send the prompt to DALL-E and receive an image as a response. You can also use image client to edit the image, such as changing the color or shape of the hat, and then use GPT-4 to generate a description of the edited image. \n",
        "\n",
        "## Objectives:\n",
        "\n",
        "1. Generate a prompt for DALL-E using GPT 3.5/4.0 model\n",
        "2. Use image client to send the prompt to DALL-E and receive an image as a response."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import libraries"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import AzureChatOpenAI\n",
        "from langchain.chains import TransformChain, LLMChain, SequentialChain\n",
        "from langchain.prompts import (\n",
        "    PromptTemplate,\n",
        "    ChatPromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    AIMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1710960974598
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get social media post from previous Lab"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the file\n",
        "with open('social_media_post.txt', 'r') as f:\n",
        "    social_media_post = f.read()\n",
        "\n",
        "# Print the content\n",
        "print(social_media_post)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1710960976039
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to Azure OpenAI service"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables\n",
        "if load_dotenv():\n",
        "    print(\"Found Azure OpenAI API Base Endpoint: \" + os.getenv(\"AZURE_OPENAI_ENDPOINT\"))\n",
        "else: \n",
        "    print(\"Azure OpenAI API Base Endpoint not found. Have you configured the .env file?\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1710960995450
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
        "api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
        "api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
        "\n",
        "model =  os.getenv(\"AZURE_OPENAI_CHAT_MODEL\")\n",
        "print(model)\n",
        "\n",
        "dalle_model = os.getenv(\"AZURE_OPENAI_DALLE_MODEL\")\n",
        "print(dalle_model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1710960999542
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use GPT model to generate prompt for DALL-E model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use GPT-4 to generate a DALL-E prompt\n",
        "system_template=\"You are a helpful large language model that generates DALL-E prompts, that when given to the DALL-E model can generate beautiful high-quality images to use in social media posts about a podcast on technology.  Good DALL-E prompts will contain mention of related objects, and will not contain people or words.  Good DALL-E prompts should include a reference to podcasting along with items from the domain of the podcast guest.\\n\"\n",
        "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
        "\n",
        "user_prompt=PromptTemplate(\n",
        "    template=\"Create a DALL-E prompt to create an image to post along with this social media text: {social_media_copy}\",\n",
        "    input_variables=[\"social_media_copy\"],\n",
        ")\n",
        "human_message_prompt = HumanMessagePromptTemplate(prompt=user_prompt)\n",
        "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
        "\n",
        "# Get formatted messages for the chat completion\n",
        "dalle_messages = chat_prompt.format_prompt(social_media_copy={social_media_post}).to_messages()\n",
        "\n",
        "# Call Azure OpenAI Service to get a DALL-E prompt \n",
        "print(\"Calling GPT-4 model on Azure OpenAI Service to get a DALL-E prompt...\\n\")\n",
        "gpt4 = AzureChatOpenAI(\n",
        "    #openai_api_base=gpt4_endpoint,\n",
        "    openai_api_version=api_version,\n",
        "    deployment_name=model,\n",
        "    #openai_api_key=gpt4_api_key,\n",
        "    openai_api_type = \"azure\",\n",
        ")\n",
        "#print(gpt4)   #shows parameters\n",
        "\n",
        "output = gpt4(dalle_messages)\n",
        "dalle_prompt = output.content\n",
        "\n",
        "dalle_prompt_chain = LLMChain(llm=gpt4, prompt=chat_prompt, output_key=\"dalle_prompt\")\n",
        "\n",
        "print(\"DALL-E Prompt:\\n\")\n",
        "print(dalle_prompt)\n",
        "print(\"\\n\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1710961008437
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save DALL-E prompt to file"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the file path\n",
        "file_path = \"dalle_prompt.txt\"\n",
        "\n",
        "# Write the content to the file\n",
        "with open(file_path, \"w\") as file:\n",
        "    file.write(dalle_prompt)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1710960231518
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Alter DALL-E prompt"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Append \"high-quality digital art\" to the generated DALL-E prompt\n",
        "dalle_prompt = dalle_prompt + \", high-quality digital art\"\n",
        "print(\"dalleprompt: \",dalle_prompt)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1710961018860
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make a call to DALL-E model on the Azure OpenAI Service to generate an image "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import AzureOpenAI\n",
        "import os\n",
        "import requests\n",
        "from PIL import Image\n",
        "import json\n",
        "\n",
        "client = AzureOpenAI(\n",
        "    api_version=\"2024-02-01\",  \n",
        "    api_key=api_key,  \n",
        "    azure_endpoint=azure_endpoint\n",
        ")\n",
        "\n",
        "result = client.images.generate(\n",
        "    model=dalle_model, # the name of your DALL-E 3 deployment\n",
        "    prompt=dalle_prompt,\n",
        "    n=1\n",
        ")\n",
        "\n",
        "json_response = json.loads(result.model_dump_json())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get and display the image"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the image path (note the filetype should be png)\n",
        "image_path = 'postImage.png'\n",
        "\n",
        "# Retrieve the generated image\n",
        "image_url = json_response[\"data\"][0][\"url\"]  # extract image URL from response\n",
        "generated_image = requests.get(image_url).content  # download the image\n",
        "with open(image_path, \"wb\") as image_file:\n",
        "    image_file.write(generated_image)\n",
        "\n",
        "# Display the image in the default image viewer\n",
        "image = Image.open(image_path)\n",
        "image"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1710961110078
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}