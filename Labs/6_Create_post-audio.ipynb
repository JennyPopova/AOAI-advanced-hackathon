{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Overview\n",
        "In this lab we will use **Azure OpenAI Text-to-Speech** model to create an audio representation of our social media post\n",
        "\n",
        "**Azure OpenAI Text-to-Speech** is an innovative service that converts text into lifelike speech. **Speech client** is a tool that enables you to interact with Azure's Text-to-Speech capabilities through an  API. GPT-4, with its advanced language understanding, can be used to generate scripts for social media posts or other audio content. By integrating these technologies, you can create engaging audio content that resonates with your audience. For instance, you can use GPT-4 to write a script for a social media announcement, and then employ the speech client to convert this script into spoken words with a choice of voices and languages. You can also customize the speech output, such as adjusting the speed or pitch, to suit the context of the post.\n",
        "\n",
        "## Steps:\n",
        "\n",
        "1. Get a social media post, created by GPT model.\n",
        "2. Utilize the speech client to transform the script into audio, selecting the appropriate voice and language settings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Get social media post from file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1710961798614
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Open the file\n",
        "with open('social_media_post.txt', 'r') as f:\n",
        "    social_media_post = f.read()\n",
        "\n",
        "# Print the content\n",
        "print(social_media_post)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Get Environment variables\n",
        "The provided code is importing the `load_dotenv` function from the `dotenv` module and using it to load environment variables from a `.env`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1710961976676
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables\n",
        "if load_dotenv():\n",
        "    print(\"Found Azure OpenAI API Base Endpoint: \" + os.getenv(\"AZURE_OPENAI_ENDPOINT\"))\n",
        "else: \n",
        "    print(\"Azure OpenAI API Base Endpoint not found. Have you configured the .env file?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1710961977836
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
        "api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
        "api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
        "\n",
        "model =  os.getenv(\"AZURE_OPENAI_TTS_MODEL\")\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Call Azure OpenAI Text-to-Speech to create audio file for the social media post\n",
        "\n",
        "This code is creating AzureOpenAI client and makes actual call to **tts** model to create an audio\n",
        "\n",
        "The available voices for the model are: `alloy`, `echo`, `fable`, `onyx`, `nova`, and `shimmer`. \n",
        "\n",
        "*You can experiment further and try your own text by assigning it to `social_media_post` variable or setting another voice*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1710961910539
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from openai import AzureOpenAI\n",
        "\n",
        "client = AzureOpenAI(\n",
        "    api_version=\"2024-02-15-preview\",  \n",
        "    api_key=api_key,  \n",
        "    azure_endpoint=azure_endpoint\n",
        ")\n",
        "\n",
        "result = client.audio.speech.create(\n",
        "    model=model, # the name of your text-to-speech deployment\n",
        "    input=social_media_post,\n",
        "    voice = \"alloy\"\n",
        ")\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Save audio file\n",
        "This Python code snippet is used to save audio output into `\"speech.mp3\"` file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1710961918655
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "speech_file_path = \"speech.mp3\"\n",
        "result.stream_to_file(speech_file_path)\n",
        "print(f\"Spoken audio generated from input text saved as {speech_file_path}\")"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
