{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "\n",
        "### LangChain Components-LLMChain and Prompt template\n",
        "\n",
        "**Langchain** is a Python library that allows you to create powerful applications using language models and prompts. **LLMChain** and **ChatPromptTemplate** are two of the main components of Langchain that enable you to generate natural language responses from various inputs.\n",
        "\n",
        "An **LLMChain** is an object that combines a prompt template and a language model. A **prompt template** is a string that defines the format and structure of the input and output for the language model. A language model is a neural network that can generate natural language text based on some input. An LLMChain takes a dictionary of key-value pairs as input, formats the prompt template using the values, passes the formatted string to the language model, and returns the language model output as a response. You can use different language models such as OpenAI, GPT-3, or Llama 2 with LLMChain.\n",
        "\n",
        "\n",
        "### Objective:\n",
        "\n",
        "To call the GPT model API from Lang chain application for getting social media copy by sending input parameters \"bio\" and \"transcript\" using ChatPromptTemplate and LLMChain.\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import AzureChatOpenAI\n",
        "from langchain.chains import TransformChain, LLMChain, SequentialChain\n",
        "from langchain.prompts import (\n",
        "    PromptTemplate,\n",
        "    ChatPromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    AIMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1710960863950
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get podcast transcript created in Lab1"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the file\n",
        "with open('transcript.txt', 'r') as f:\n",
        "    transcript = f.read()\n",
        "\n",
        "# Print the content\n",
        "print(transcript)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1710960864415
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get biography created in Lab3"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the file\n",
        "with open('bio.txt', 'r') as f:\n",
        "    bio = f.read()\n",
        "\n",
        "# Print the content\n",
        "print(bio)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1710960864580
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to Azure OpenAI service"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables\n",
        "if load_dotenv():\n",
        "    print(\"Found Azure OpenAI API Base Endpoint: \" + os.getenv(\"AZURE_OPENAI_ENDPOINT\"))\n",
        "else: \n",
        "    print(\"Azure OpenAI API Base Endpoint not found. Have you configured the .env file?\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1710960864704
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
        "api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
        "api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
        "\n",
        "model =  os.getenv(\"AZURE_OPENAI_CHAT_MODEL\")\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1710960864830
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Put transcript and bio into the prompt"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_template=\"You are a helpful large language model that can create a LinkedIn promo blurb for episodes of the podcast Behind the Tech, when given transcripts of the podcasts.  The Behind the Tech podcast is hosted by Kevin Scott.\\n\"\n",
        "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
        "\n",
        "user_prompt=PromptTemplate(\n",
        "    template=\"Create a short summary of this podcast episode that would be appropriate to post on LinkedIn to promote the podcast episode.  The post should be from the first-person perspective of Kevin Scott, who hosts the podcast.\\n\" +\n",
        "            \"Here is the transcript of the podcast episode: {transcript} \\n\" +\n",
        "            \"Here is the bio of the guest: {bio} \\n\",\n",
        "    input_variables=[\"transcript\", \"bio\"],\n",
        ")\n",
        "human_message_prompt = HumanMessagePromptTemplate(prompt=user_prompt)\n",
        "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
        "\n",
        "# Get formatted messages for the chat completion\n",
        "blurb_messages = chat_prompt.format_prompt(transcript={transcript}, bio={bio}).to_messages()\n",
        "blurb_messages"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1710960864980
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Send request to GPT model to create a LinkedIn post"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a call to Azure OpenAI Service to get a social media blurb, \n",
        "print(\"Calling GPT-4 model on Azure OpenAI Service to get a social media blurb...\\n\")\n",
        "gpt = AzureChatOpenAI(\n",
        "    #openai_api_base=azure_endpoint,\n",
        "    openai_api_version=api_version,\n",
        "    deployment_name=model,\n",
        "    #openai_api_key=api_key,\n",
        "    openai_api_type = \"azure\",\n",
        ")\n",
        "#print(gpt4)   #shows parameters\n",
        "\n",
        "output = gpt(blurb_messages)\n",
        "social_media_post = output.content\n",
        "\n",
        "gpt4_chain = LLMChain(llm=gpt, prompt=chat_prompt, output_key=\"social_media_copy\")\n",
        "\n",
        "print(\"Social Media Copy:\\n\")\n",
        "print(social_media_post)\n",
        "print(\"\\n\")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1710960874743
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save Social media post to file"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the file path\n",
        "file_path = \"social_media_post.txt\"\n",
        "\n",
        "# Write the content to the file\n",
        "with open(file_path, \"w\") as file:\n",
        "    file.write(social_media_post)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1710960874903
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}